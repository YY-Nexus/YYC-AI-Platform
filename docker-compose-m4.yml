version: '3.8'

services:
  # MySQL数据库 - 利用你的本地MySQL
  # mysql:
  #   image: mysql:8.0
  #   container_name: ai_platform_mysql
  #   environment:
  #     MYSQL_ROOT_PASSWORD: rootpassword
  #     MYSQL_DATABASE: ai_platform
  #     MYSQL_USER: ai_user
  #     MYSQL_PASSWORD: ai_password
  #   ports:
  #     - "3306:3306"  # 统一使用3306端口
  #   volumes:
  #     - mysql_data:/var/lib/mysql
  #     - ./init.sql:/docker-entrypoint-initdb.d/init.sql
  #   command: 
  #     - --performance-schema=ON
  #     - --innodb-buffer-pool-size=2G
  #     - --innodb-log-file-size=512M
  #   networks:
  #     - ai_network

  # 使用本地MySQL（推荐）
  # 跳过mysql服务，直接使用本地MySQL

  # AI聊天服务 - 优化M4性能
  ai-chat:
    build: 
      context: ./ai-chat-service
      dockerfile: Dockerfile.m4
    container_name: ai_platform_chat
    ports:
      - "8001:8000"
    volumes:
      - ./ai-chat-service:/app
      - model_cache:/app/models
    environment:
      - DATABASE_URL=mysql://ai_user:ai_password@host.docker.internal:3306/ai_platform
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - OLLAMA_HOST=host.docker.internal
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
    networks:
      - ai_network

  # 可视化编程界面
  visual-programming:
    build: 
      context: ./visual-programming
      dockerfile: Dockerfile.m4
    container_name: ai_visual_programming
    ports:
      - "8501:8501"
    volumes:
      - ./visual-programming:/app
      - ./shared_workspace:/app/workspace
    environment:
      - API_URL=http://ai-chat:8000
      - API_URL_LOCAL=http://localhost:8001
      - GITEA_URL=http://gitea:3000
    deploy:
      resources:
        limits:
          memory: 4G
    networks:
      - ai_network

  # Ollama本地模型服务
  ollama:
    image: ollama/ollama:latest
    container_name: ai_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./ollama-models:/models
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_PARALLEL=4
    deploy:
      resources:
        limits:
          memory: 64G  # 充分利用128GB内存
          cpus: "8.0"
    networks:
      - ai_network

  # 实时预览服务
  preview-server:
    build: 
      context: ./preview-server
      dockerfile: Dockerfile.m4
    container_name: ai_preview_server
    ports:
      - "3001:3001"
    volumes:
      - ./shared_workspace:/app/workspace
      - ./preview-server:/app
    environment:
      - NODE_ENV=development
    networks:
      - ai_network

volumes:
  mysql_data:
  ollama_data:
  model_cache:
  shared_workspace:

networks:
  ai_network:
    driver: bridge